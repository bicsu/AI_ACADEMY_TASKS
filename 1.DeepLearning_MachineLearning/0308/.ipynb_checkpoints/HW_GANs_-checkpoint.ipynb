{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GAN.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "(train_data, train_label), (test_data, test_label) = cifar10.load_data()\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "def img_tile(imgs, aspect_ratio=1.0, tile_shape=None, border=1,\n",
    "             border_color=0):\n",
    "    ''' Tile images in a grid.\n",
    "    If tile_shape is provided only as many images as specified in tile_shape\n",
    "    will be included in the output.\n",
    "    '''\n",
    "\n",
    "    imgs = np.array(imgs)\n",
    "    if imgs.ndim != 3 and imgs.ndim != 4:\n",
    "        raise ValueError('imgs has wrong number of dimensions.')\n",
    "    n_imgs = imgs.shape[0]\n",
    "\n",
    "    # Grid shape\n",
    "    img_shape = np.array(imgs.shape[1:])\n",
    "    if tile_shape is None:\n",
    "        img_aspect_ratio = img_shape[1] / float(img_shape[0])\n",
    "        aspect_ratio *= img_aspect_ratio\n",
    "        tile_height = int(np.ceil(np.sqrt(n_imgs * aspect_ratio)))\n",
    "        tile_width = int(np.ceil(np.sqrt(n_imgs / aspect_ratio)))\n",
    "        grid_shape = np.array((tile_height, tile_width))\n",
    "    else:\n",
    "        assert len(tile_shape) == 2\n",
    "        grid_shape = np.array(tile_shape)\n",
    "\n",
    "    # Tile image shape\n",
    "    tile_img_shape = np.array(imgs.shape[1:])\n",
    "    tile_img_shape[:2] = (img_shape[:2] + border) * grid_shape[:2] - border\n",
    "\n",
    "    # Assemble tile image\n",
    "    tile_img = np.empty(tile_img_shape)\n",
    "    tile_img[:] = border_color\n",
    "    for i in range(grid_shape[0]):\n",
    "        for j in range(grid_shape[1]):\n",
    "            img_idx = j + i * grid_shape[1]\n",
    "            if img_idx >= n_imgs:\n",
    "                # No more images - stop filling out the grid.\n",
    "                break\n",
    "            img = imgs[img_idx]\n",
    "            yoff = (img_shape[0] + border) * i\n",
    "            xoff = (img_shape[1] + border) * j\n",
    "            tile_img[yoff:yoff + img_shape[0], xoff:xoff + img_shape[1], ...] = img\n",
    "\n",
    "    return tile_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# size of CIFAR10\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "idx = np.random.randint(0, train_data.shape[0])\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[idx]\n",
    "ax1.imshow(sample_data);\n",
    "# ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete summary folder and make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_DIR = './gan_summary'\n",
    "TRAIN_DIR = SUMMARY_DIR + '/train'\n",
    "TEST_DIR = SUMMARY_DIR + '/test'\n",
    "IMAGE_DIR = SUMMARY_DIR + '/image'\n",
    "\n",
    "if os.path.exists(SUMMARY_DIR):\n",
    "    shutil.rmtree(SUMMARY_DIR)\n",
    "if not os.path.exists(SUMMARY_DIR):\n",
    "    os.makedirs(SUMMARY_DIR)\n",
    "    os.makedirs(TRAIN_DIR)\n",
    "    os.makedirs(TEST_DIR)\n",
    "    os.makedirs(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(inputs, out_channel, name='fc'):\n",
    "    \"\"\"\n",
    "    very simple fully connected layer function\n",
    "\n",
    "    Args:\n",
    "        inputs: a batch of input tensor [batch_size, n]\n",
    "                where n is the number of input feature dimension\n",
    "        out_channel: output channel dimension\n",
    "\n",
    "    Returns:\n",
    "        fc: inputs * weights + biases [batch_size, out_channel]\n",
    "    \"\"\"\n",
    "    # in_channel: input channel dimension\n",
    "    # w_shape: shape of weight matrix\n",
    "    # b_shape: shape of bias vector\n",
    "    in_channel = inputs.get_shape().as_list()[1]\n",
    "    w_shape = [in_channel, out_channel]\n",
    "    b_shape = [out_channel]\n",
    "\n",
    "    # Define weight matrix variable, bias vector variable\n",
    "    with tf.variable_scope(name):\n",
    "        # To share the variables you have to use\n",
    "        # a function 'tf.get_variable' instead of 'tf.Variable'\n",
    "        weights = tf.get_variable('weights', shape=w_shape,\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        biases = tf.get_variable('biases', shape=b_shape,\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        fc = tf.matmul(inputs, weights)\n",
    "        fc = tf.nn.bias_add(fc, biases)\n",
    "\n",
    "        return fc\n",
    "\n",
    "def conv2d(input_, output_dim, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02, name=\"conv2d\"):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
    "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
    "\n",
    "        return conv\n",
    "\n",
    "def bn(x, is_training, scope, axis=-1):\n",
    "    return tf.layers.batch_normalization(x, epsilon = 1e-5, momentum = 0.9, training = is_training, name = scope, axis=axis) # add axis=1\n",
    "\n",
    "def linear(input_, output_size, scope=None, stddev=0.02, bias_start=0.0, with_w=False):\n",
    "    shape = input_.get_shape().as_list()\n",
    "\n",
    "    with tf.variable_scope(scope or \"Linear\"):\n",
    "        matrix = tf.get_variable(\"Matrix\", [shape[1], output_size], tf.float32,\n",
    "                 tf.random_normal_initializer(stddev=stddev))\n",
    "        bias = tf.get_variable(\"bias\", [output_size],\n",
    "        initializer=tf.constant_initializer(bias_start))\n",
    "        if with_w:\n",
    "            return tf.matmul(input_, matrix) + bias, matrix, bias\n",
    "        else:\n",
    "            return tf.matmul(input_, matrix) + bias\n",
    "\n",
    "def deconv2d(input_, output_shape, k_h=5, k_w=5, d_h=2, d_w=2, name=\"deconv2d\", stddev=0.02, with_w=False):\n",
    "    with tf.variable_scope(name):\n",
    "        # filter : [height, width, output_channels, in_channels]\n",
    "        w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n",
    "                            initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "        try:\n",
    "            deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        # Support for verisons of TensorFlow before 0.7.0\n",
    "        except AttributeError:\n",
    "            deconv = tf.nn.deconv2d(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
    "        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n",
    "\n",
    "        if with_w:\n",
    "            return deconv, w, biases\n",
    "        else:\n",
    "            return deconv\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: (100, 32, 32, 3)\n",
      "D: (100, 16, 16, 64)\n",
      "D: (100, 8, 8, 128)\n",
      "D: (100, 4, 4, 256)\n",
      "D: (100, 2, 2, 512)\n",
      "D: (100, 2048)\n",
      "D: (100, 2048)\n",
      "D: (100, 1)\n",
      "------------------------\n",
      "G: (100, 128)\n",
      "G: (100, 2048)\n",
      "G: (100, 2, 2, 512)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 8, 8, 128)\n",
      "G: (100, 16, 16, 64)\n",
      "G: (100, 32, 32, 3)\n",
      "------------------------\n",
      "D: (100, 32, 32, 3)\n",
      "D: (100, 16, 16, 64)\n",
      "D: (100, 8, 8, 128)\n",
      "D: (100, 4, 4, 256)\n",
      "D: (100, 2, 2, 512)\n",
      "D: (100, 2048)\n",
      "D: (100, 2048)\n",
      "D: (100, 1)\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "def discriminator(x, reuse=None, is_training=True):\n",
    "    \"\"\"\n",
    "    build the discriminator\n",
    "\n",
    "    Args:\n",
    "        x: a batch of input to the network [batch_size, 32, 32, 3]\n",
    "\n",
    "    returns:\n",
    "        net: output of the discriminator [batch_size, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "#             if self.dataset_name == 'cifar10':\n",
    "        if True:\n",
    "            print(\"D:\",x.get_shape()) # 32, 32, 3 = 3072\n",
    "            net = lrelu(conv2d(x, 64, 5, 5, 2, 2, name='d_conv1'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = lrelu(bn(conv2d(net, 128, 5, 5, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = lrelu(bn(conv2d(net, 256, 5, 5, 2, 2, name='d_conv3'), is_training=is_training, scope='d_bn3'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = lrelu(bn(conv2d(net, 512, 5, 5, 2, 2, name='d_conv4'), is_training=is_training, scope='d_bn4'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = tf.reshape(net, [batch_size, -1])\n",
    "            print(\"D:\",net.get_shape())\n",
    "            out_logit = linear(net, 1, scope='d_fc5')\n",
    "            print(\"D:\",net.get_shape())\n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "            print(\"D:\",out.get_shape())\n",
    "            print(\"------------------------\")\n",
    "\n",
    "        else: # mnist / fashion mnist\n",
    "            #print(x.get_shape())\n",
    "            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n",
    "            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n",
    "            net = tf.reshape(net, [batch_size, -1])\n",
    "            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n",
    "            out_logit = linear(net, 1, scope='d_fc4')\n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "\n",
    "        return out\n",
    "\n",
    "def generator(z, is_training=True):\n",
    "    \"\"\"\n",
    "    build the generator\n",
    "\n",
    "    Args:\n",
    "        z: a batch of input to the network [batch_size, z_dim]\n",
    "\n",
    "    Returns:\n",
    "        net: output of the generator [batch_size, 28, 28, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "\n",
    "        h_size = 32\n",
    "        h_size_2 = 16\n",
    "        h_size_4 = 8\n",
    "        h_size_8 = 4\n",
    "        h_size_16 = 2\n",
    "\n",
    "        print(\"G:\",z.get_shape())\n",
    "        net = linear(z, 512*h_size_16*h_size_16, scope='g_fc1')\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(tf.reshape(net, [batch_size, h_size_16, h_size_16, 512]),is_training=is_training, scope='g_bn1')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(deconv2d(net, [batch_size, h_size_8, h_size_8, 256], 5, 5, 2, 2, name='g_dc2'),is_training=is_training, scope='g_bn2')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(deconv2d(net, [batch_size, h_size_4, h_size_4, 128], 5, 5, 2, 2, name='g_dc3'),is_training=is_training, scope='g_bn3')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(deconv2d(net, [batch_size, h_size_2, h_size_2, 64], 5, 5, 2, 2, name='g_dc4'),is_training=is_training, scope='g_bn4')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        out = tf.nn.sigmoid(\n",
    "            deconv2d(net, [batch_size, 32, 32, 3], 5, 5, 2, 2, name='g_dc5')\n",
    "            )\n",
    "        print(\"G:\",out.get_shape())\n",
    "        print(\"------------------------\")\n",
    "    return out\n",
    "\n",
    "def get_loss(D_real, D_fake, eps=1e-10):\n",
    "    \"\"\"\n",
    "    get loss of GAN\n",
    "\n",
    "    Args:\n",
    "        D_real: Real Discriminator output [batch_size, 1]\n",
    "        D_fake: Fake discriminator output [batch_size, 1]\n",
    "\n",
    "    Returns:\n",
    "        D_loss: Discriminator loss\n",
    "        G_loss: Generator loss\n",
    "    \"\"\"\n",
    "    D_loss = -(tf.reduce_mean(tf.log(D_real+eps)) + tf.reduce_mean(tf.log(1-D_fake+eps)))\n",
    "    G_loss = -tf.reduce_mean(tf.log(D_fake+eps))\n",
    "\n",
    "    return D_loss, G_loss\n",
    "\n",
    "\n",
    "def get_next_batch(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    get 'batch_size' amount of data and label randomly\n",
    "\n",
    "    Args:\n",
    "        data: data\n",
    "        label: label\n",
    "        batch_size: # of data to get\n",
    "\n",
    "    Returns:\n",
    "        batch_data: data of 'batch_size'\n",
    "        batch_label: coresponding label of batch_data\n",
    "    \"\"\"\n",
    "    n_data = data.shape[0]\n",
    "    random_idx = random.sample(range(1, n_data), batch_size)\n",
    "\n",
    "    batch_data = data[random_idx]\n",
    "    batch_label = label[random_idx]\n",
    "    return batch_data, batch_label\n",
    "\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 100\n",
    "z_dim = 128\n",
    "max_step = 20000\n",
    "lrD = 1e-3\n",
    "lrG = 1e-4\n",
    "beta1 = 0.5\n",
    "\n",
    "############################# Build the model #############################\n",
    "# Define image tensor x placeholder\n",
    "x = tf.placeholder(tf.float32, [batch_size, 32, 32, 3], name='input_x')\n",
    "# Define z vector as uniform distribution between [-1, 1]\n",
    "z = tf.random_uniform((batch_size, z_dim), -1., 1.,\n",
    "                      name='latent_z') # Random한 constant 생성\n",
    "\n",
    "# Build discriminator where input data is real image x\n",
    "D_real = discriminator(x, reuse=False) #x가 들어왔을 때 build했을 때 get_variable를 만들지 않았을니깐 False\n",
    "# Build generator\n",
    "G = generator(z)\n",
    "# Build discriminator where input data is generated image G\n",
    "D_fake = discriminator(G, reuse=True) #get_variable을 그대로 씀. Weight가 같아야함. 아까 만들었떤 w를 reuse해서 계산할거야라고 선언\n",
    "\n",
    "# Get D_loss and G_loss\n",
    "D_loss, G_loss = get_loss(D_real, D_fake)\n",
    "\n",
    "# Make optimization op\n",
    "opt = tf.train.AdamOptimizer(lrD, beta1=beta1)\n",
    "\n",
    "# To update the generator and the discriminator\n",
    "# get their network parameters\n",
    "G_params = [param for param in tf.trainable_variables()\n",
    "            if 'generator' in param.name]\n",
    "D_params = [param for param in tf.trainable_variables()\n",
    "            if 'discriminator' in param.name]\n",
    "\n",
    "# Make train op for each network\n",
    "D_train = opt.minimize(D_loss, var_list=D_params)\n",
    "G_train = opt.minimize(G_loss, var_list=G_params)\n",
    "\n",
    "# Make initialization op\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[5,5,256,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node discriminator/d_conv4/w/Adam_1/Assign (defined at <ipython-input-6-612284ad9e89>:164)  = Assign[T=DT_FLOAT, _class=[\"loc:@discriminator/d_conv4/w/Assign\"], _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](discriminator/d_conv4/w/Adam_1, discriminator/d_conv4/w/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'discriminator/d_conv4/w/Adam_1/Assign', defined at:\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-612284ad9e89>\", line 164, in <module>\n    D_train = opt.minimize(D_loss, var_list=D_params)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 410, in minimize\n    name=name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 593, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 136, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 1139, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1481, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[5,5,256,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node discriminator/d_conv4/w/Adam_1/Assign (defined at <ipython-input-6-612284ad9e89>:164)  = Assign[T=DT_FLOAT, _class=[\"loc:@discriminator/d_conv4/w/Assign\"], _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](discriminator/d_conv4/w/Adam_1, discriminator/d_conv4/w/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5,5,256,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node discriminator/d_conv4/w/Adam_1/Assign}} = Assign[T=DT_FLOAT, _class=[\"loc:@discriminator/d_conv4/w/Assign\"], _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](discriminator/d_conv4/w/Adam_1, discriminator/d_conv4/w/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dd6aa716a5c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Initialize variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Before train the model, shows train data and save it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5,5,256,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node discriminator/d_conv4/w/Adam_1/Assign (defined at <ipython-input-6-612284ad9e89>:164)  = Assign[T=DT_FLOAT, _class=[\"loc:@discriminator/d_conv4/w/Assign\"], _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](discriminator/d_conv4/w/Adam_1, discriminator/d_conv4/w/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'discriminator/d_conv4/w/Adam_1/Assign', defined at:\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-612284ad9e89>\", line 164, in <module>\n    D_train = opt.minimize(D_loss, var_list=D_params)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 410, in minimize\n    name=name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 593, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 136, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 1139, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1481, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[5,5,256,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node discriminator/d_conv4/w/Adam_1/Assign (defined at <ipython-input-6-612284ad9e89>:164)  = Assign[T=DT_FLOAT, _class=[\"loc:@discriminator/d_conv4/w/Assign\"], _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](discriminator/d_conv4/w/Adam_1, discriminator/d_conv4/w/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Define writer\n",
    "    train_writer = tf.summary.FileWriter(TRAIN_DIR, sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(TEST_DIR)\n",
    "\n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Before train the model, shows train data and save it\n",
    "    batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "    train_tiled = img_tile(batch_x, border_color=1.0)\n",
    "    train_tiled = np.squeeze(train_tiled)\n",
    "    print(\"Training data\")\n",
    "    plt.imshow(train_tiled)\n",
    "    plt.show()\n",
    "    plt.imsave(IMAGE_DIR + '/train.png', train_tiled)\n",
    "    \n",
    "    samples = []\n",
    "    for step in range(max_step):\n",
    "        batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "        \n",
    "        _, d_loss = sess.run([D_train, D_loss], feed_dict={x: batch_x})\n",
    "        _, g_loss = sess.run([G_train, G_loss])\n",
    "        #summary = sess.run(merged, feed_dict={x: batch_x})\n",
    "        #train_writer.add_summary(summary, step)\n",
    "        \n",
    "        # Save generarted data to make gif files\n",
    "        if step % 50 == 0:\n",
    "            g = sess.run(G)\n",
    "            g_tiled = img_tile(g, border_color=1.0)\n",
    "            g_tiled = np.squeeze(g_tiled)\n",
    "            samples.append(g_tiled)\n",
    "        if step % 200 == 0:\n",
    "            print(\"{} steps |  G_loss: {:.4f}, D_loss: {:.4f}\".format(step, g_loss, d_loss))\n",
    "            plt.imshow(g_tiled)\n",
    "            plt.show()\n",
    "            plt.imsave(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)),\n",
    "                       g_tiled)\n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.mimsave(SUMMARY_DIR + '/generated.gif', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "https://github.com/4thgen/DCGAN-CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
